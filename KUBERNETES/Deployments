======= Deployments has two main feature HA and Scaling =========

1. HA
------

Till now we see PODs, Namespace, Labels and basics yaml concepts

===> We created pods and if we deleted pods then we can not bring the pod again automatically, we need to create new one, but manually we need to create. so this is called as NO HA. We need some HA mecahnisum so if the pod is deleted it can be created automatically.

===> Now we some HA functionality in the form of Deployments, we have 6 types of Deployments strategy:
1. Pod: (No HA, No Scaling)
2. Replication Controller (RC): (HA Scaling)
3. Replication Set (RS): (HA Scaling)
4. Deployment (RC, RS, ROLLOUT, ROLLBACK)
5. Daemon Sets 
6. Static Pods

--> We see pods creation but, we can not get any HA to control, If we deployed one application and suddenly load has been increased so we can not control like create some more replicas for pods or any HA feature.

--> Now we have one feature i.e Replication feature, at the end this is also creating pods but now these feature will manage pods, in market 1st came RC and then RS both providing same feature but now we have one feature i.e. Deployment this feature have both functionality with others functionality also now in market this Deployment feature used only for pod or namespace or etc., will see this now.

--> Now we have one pod deployment scenario (go to diagram), this will manage pods. go to kubernets.io site and search deployment and copy below deployment code for pods and go to master terminal and create one deployment.yaml file and paste copied code into this file.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
  (we can define here namespace also namespace: <name> )
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80

--> Now pod creation will manage by above deployment code

--> (metadata)-- provides name to this deployment and labels
--> (spec)-- provides replicas, selector, template 
		--> {replicas}- here we can define how many pods we need to create 3 or any number, 
						this replicas came from replication control.
		--> {selector}- 
		--> {template}- this template is pods template, all data is template data, 
						when the pod will create by deployment, its uses this template data 

(Note - template label and selector label must be same)

--> Create deployment file   						
# Kubectl create -f deployment.yaml 
		or 
# kubectl create -f deployment.yaml -n <namespace-name>

--> now will check most imp feature is HA

- delete any pod and it will create automatically
# kubectl delete pod <name>

(Note - now kube controller will take this responsibility to maintain 5 pods for this deployment, if any pod deleted then it will create new pod immediatly by kub controller)

--> describe pod and check owner reference
# kubectl describe pod <pod-name>

--> list deployment
# kubectl get deployment

===============================

2. Scaling
----------

--> Scaling has two types horizantal and vertical scaling, but k8s works on horizantal scaling only.
now we will see manual horizantal scaling. for auto horizantal scaling we need matrix server.
ex. If application load has been increased suddenly and we need more pods immediatly so we can create new pods immediatly using below cmd

# kubectl scale deployment <deployment-name> --replicas <number>
					or
					
# kubectl edit deployment.apps <deployment-name> (using this cmd we are entered into the etcd data directly and will change replicas number and save it, pods will be created)
					or (we can go to deployment.yaml file and make changes to replicas and run the file)
# kubectl create -f deployment.yaml 

---> list all 
# kubectl get all

===============
DaemonSets
==============

# vi deployment.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-deployment
  labels:
    app: nginx
  (we can define here namespace also namespace: <name> )
spec:
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
		
# kubectl create -f deployment.yaml

# kubectl get nodes 

# kubectl describe node master 

Note - replica will not create on master due to some taints has been define

# kubectl create deployment test --image nginx --replicas=3

-- above cmd will create replicas on any node, but if we want to create only replicas on specified node then Daemon sets is best option

# kubectl get ds -A

-- no of nodes = no of replicas

# kubectl get pods -o wide -n <ds-name>

--- whenever we add any new node then daemon set automatically create replicas(pod) on new node (pod creation manage by kubelet)

===============
Static Pod
===============

pod which is not manage by kubernetes, So I need create pod on node directly 

# kubectl get node

-- go to any node

# ssh node1.cka.com -p 2289

-- create one yaml file 

# cd /etc/kubernetes/manifests/static-web.yaml (this file maintain by kubelet)

kubectl run test --image nginx --dry-run=client -o yaml >  /etc/kubernetes/manifests/static-web.yaml 

or 

add below code into yaml file

mkdir -p /etc/kubernetes/manifests/
cat <<EOF >/etc/kubernetes/manifests/static-web.yaml
apiVersion: v1
kind: Pod
metadata:
  name: static-web
  labels:
    role: myrole
spec:
  containers:
    - name: web
      image: nginx
      ports:
        - name: web
          containerPort: 80
          protocol: TCP
EOF

-- we just need to create yaml file for pod creation and pod will be created automatically 
-- also we are trying for delete then pod will not deleted 
-- if we want to delete then delete yaml file from manifest 

=====================
Scheduling
===============
-- for scheduling kube scheduler is responsible 
 
1. cordon and uncordon
-------------------

-- If we want to disable pod creation on any node for some time or day.
# kubectl cordon node1.cka.com (using this cmd scheduling is disabled)

-- try to create pod, so pod will not generate
# Kubectl create deployment test2 --image nginx --replicas 5 

-- enable scheduling
# kubectl uncordon node1.cka.com

2. drain
-----

drain is like cordon + delete all the resources
# kubectl drain node1.cka.com

-- drain delete only those pods that is manage by cluster, drain will not delete pod i.e manage by daemon sets

use --force and --ignore-daemonsets

# kubectl get nodes

-- now apply uncordon
# kubectl uncordon node1.cka.com

=======
3. NodeName
======= 
-- Its hard scheduling, it will bypass kube-scheduler, means if we disable schedulig on any node,
 then we can not create any resources, but using NOdeName we can create, thats why its called as hard scheduling
 
 # kubectl get all 
 
 # kubectl delete pod,ns and deployment
 
 # kubectl get nodes
 
 # vi deployment.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
	  nodeName: node1.cka.com
      containers:
      - name: nginx
        image: nginx:1.14.2
        
# kubectl create -f deployment.yaml

# kubectl get pods
 or 
 -o wide 
 
we need to see hard schedulig, so cordon any node

# kubectl cordon node-name

# kubectl create -f deployment.yaml (again)

# kubectl get pods -o wide

try to create pod on run command

# kubectl run web3 --image nginx

# kubectl get pods -o wide

=============
NodeSelector
=============

# kubectl uncordon node1 and node2

# apply label on both node

# vi deployment.yaml
apiVersion: apps/v1
kind: deployment 
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
	  nodeSelector:
		app: <label-name>
      containers:
      - name: nginx
        image: nginx:1.14.2

# kubectl create -f deployment.yaml 

# kubectl get pods -o wide 

(nodename will use only single node, for all node we will use nodeselector )

if we apply cordon, we did not crate pods using nodeSelector

-- try cordon and create pod creation

=========
Taints & toleration
=========

tains is depend on theree things key,value,
effect-  Noschedule-- means will not apply schedlue 
prefernoschedule - schedlue is not fixed ()
noexecute-- means no pod available

# kubectl describe node master (here default noschedule)

create taints
# kubectl taint node node1.cka.com corona=virus:Noschedule (Noschedule will not delete exist pods and will create new pods also)

# kubectl describe node node1 (tains has been applied here )

# kubectl get pods -o wide 

# vi deployment.yaml
apiVersion: apps/v1
kind: deployment
metadata:
  name: taint
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
	  nodeSelector: node1
      containers:
      - name: nginx
        image: nginx:1.14.2

# create -f 

# get pods -o 

# vi deployment.yaml
apiVersion: apps/v1
kind: deployment
metadata:
  name: taint
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
	  nodeSelector: 
	  app: test 
      containers:
      - name: nginx
        image: nginx:1.14.2
		
# check label on nodes is there any exist or not 

# create -f 

# get pods 

if now we need to apply toleration

# vi deployment.yaml
apiVersion: apps/v1
kind: deployment
metadata:
  name: taint
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
	  toleration:
	   key: corona
	   value: "virus"
	   effect: "Noschedule"
	  nodeSelector: 
	  app: test 
      containers:
      - name: nginx
        image: nginx:1.14.2
		
# kubectl apply -f deployment.yaml

# get pods


